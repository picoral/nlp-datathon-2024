---
title: "UA Women's+ Hackathon"
format: html
---

## Natural Language Processing with Disaster Tweets

* Log in to [kaggle.com](https://www.kaggle.com/) and access the [competition page](https://www.kaggle.com/competitions/nlp-getting-started/overview)
* Click on the black `Join Competiton` button on the top right
* We are going to be using a kaggle notebook to submit to this competition -- click on `Code` and then `+ New Notebook`
* The kaggle notebook will be created with some code for you, including code to print out the file paths to the train and test data sets
* In addition to `numpy` and `pandas`, we will be using some functions from `sklearn`

```{python}
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from sklearn import feature_extraction, linear_model, model_selection, preprocessing, svm
```

* We are going to read in the train and test file using the `read_csv` function from pandas.

```{python}
train_df = pd.read_csv("kaggle/input/nlp-getting-started/train.csv")
test_df = pd.read_csv("kaggle/input/nlp-getting-started/test.csv")
```

* We can list the variable (column) names using the `.columns` property call:

```{python}
train_df.columns
```

* We can also look at the first few observations using the `.head()` method:

```{python}
train_df.head()
```

* We can look at the first observations of a specific column by adding the column name between square brackets to the data frame:

```{python}
train_df["text"].head()
```
The target is a binary variable that is `1` when the tweet is referring to a disaster, and `0` otherwise.

```{python}
train_df.groupby("target").size()
```


## Feature extraction

* There are a number of ways to convert text to numeric variables. Let's start with scikit-learn's `CountVectorizer` to count the words in each tweet.

```{python}
count_vectorizer = feature_extraction.text.CountVectorizer()
```

```{python}
train_vectors = count_vectorizer.fit_transform(train_df["text"])
test_vectors = count_vectorizer.transform(test_df["text"])
print(train_vectors.toarray())
print(train_vectors[0])
```


* Check the [documentation page for CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)

```{python}
my_vocabulary = ["disaster", "fire", "earthquake", "shelter in place"]
count_vectorizer = feature_extraction.text.CountVectorizer(vocabulary=my_vocabulary)
```

```{python}
train_vectors = count_vectorizer.fit_transform(train_df["text"])
test_vectors = count_vectorizer.transform(test_df["text"])
print(train_vectors[0].toarray())
```

```{python}
count_vectorizer = feature_extraction.text.CountVectorizer(stop_words='english')
```

```{python}
train_vectors = count_vectorizer.fit_transform(train_df["text"])
test_vectors = count_vectorizer.transform(test_df["text"])
print(train_vectors[0].toarray())
```

Instead of counts, we can use [tf-idf (term frequency inverted document frequency)](https://www.tidytextmining.com/tfidf)

```{python}
tfid_vectorizer = feature_extraction.text.TfidfVectorizer(stop_words='english')
train_vectors_tfid = tfid_vectorizer.fit_transform(train_df["text"])
test_vectors_tfid = tfid_vectorizer.transform(test_df["text"])
print(train_vectors_tfid[0])
```
## Models

### Ridge Classifier

```{python}
clf = linear_model.RidgeClassifier()
```

```{python}
scores = model_selection.cross_val_score(clf, train_vectors, train_df["target"], cv=5, scoring="f1")
scores
```

```{python}
scores = model_selection.cross_val_score(clf, train_vectors_tfid, train_df["target"], cv=5, scoring="f1")
scores
```

### Logistic Regression

```{python}
logistic = linear_model.LogisticRegression()
scores = model_selection.cross_val_score(logistic, train_vectors, train_df["target"], cv=5, scoring="f1")
scores
```


### Suport Vector Machines

```{python}
support_vector = svm.SVC(gamma='auto')
scores = model_selection.cross_val_score(support_vector, train_vectors, train_df["target"], cv=2, scoring="f1")
scores
```

## Creating a submission file

```{python}
logistic.fit(train_vectors, train_df["target"])
sample_submission = pd.read_csv("kaggle/input/nlp-getting-started/sample_submission.csv")
sample_submission["target"] = logistic.predict(test_vectors)
sample_submission.to_csv("submission.csv", index=False)
```

