---
title: "NPL datathon -- 2024"
format: revealjs
---

## Natural Language Processing with Disaster Tweets

Link to these slides: [bit.ly/nlp-wh-2024](https://bit.ly/nlp-wh-2024)

![](images/bit.ly_nlp-wh-2024.png)

## Set up

* Log in to [kaggle.com](https://www.kaggle.com/) and access the [competition page](https://www.kaggle.com/competitions/nlp-getting-started/overview)
* Click on the black `Join Competiton` button on the top right
* We are going to be using a kaggle notebook to submit to this competition -- click on `Code` and then `+ New Notebook`
* The kaggle notebook will be created with some code for you, including code to print out the file paths to the train and test data sets

## Set up

* In addition to `numpy` and `pandas`, we will be using some functions from `sklearn`

```{python}
#| echo: true
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from sklearn import feature_extraction, linear_model, model_selection, preprocessing, svm
```

## reading in data

* We are going to read in the train and test file using the `read_csv` function from pandas.

```{python}
#| echo: true
train_df = pd.read_csv("kaggle/input/nlp-getting-started/train.csv")
test_df = pd.read_csv("kaggle/input/nlp-getting-started/test.csv")
```

* We can list the variable (column) names using the `.columns` property call:

```{python}
#| echo: true
train_df.columns
```

## Inspecting data

* We can also look at the first few observations using the `.head()` method:

```{python}
#| echo: true
train_df.head()
```

## Inspecting data

* We can look at the first observations of a specific column by adding the column name between square brackets to the data frame:

```{python}
#| echo: true
train_df["text"].head()
```

## Inspecting data

The target is a binary variable that is `1` when the tweet is referring to a disaster, and `0` otherwise.

```{python}
#| echo: true
train_df.groupby("target").size()
```

## Feature extraction

* There are a number of ways to convert text to numeric variables. Let's start with scikit-learn's `CountVectorizer` to count the words in each tweet.

```{python}
#| echo: true
count_vectorizer = feature_extraction.text.CountVectorizer()
```

```{python}
#| echo: true
train_vectors = count_vectorizer.fit_transform(train_df["text"])
test_vectors = count_vectorizer.transform(test_df["text"])
print(train_vectors.toarray())
print(train_vectors[0])
```

## Feature extraction

* Check the [documentation page for CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)

* Read the [sklearn documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text) if you want to learn about what ways to extract features from text


## Model validation

For all the models, we will evaluate a score (F1) by cross-validation.

![](images/grid_search_cross_validation.png)


## Model validation

![](images/github-recovery-codes.png)

## Ridge Classifier

```{python}
tfid_vectorizer = feature_extraction.text.TfidfVectorizer(stop_words='english')
train_vectors_tfid = tfid_vectorizer.fit_transform(train_df["text"])
test_vectors_tfid = tfid_vectorizer.transform(test_df["text"])
```

[Documentation](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression)

```{python}
#| echo: true
clf = linear_model.RidgeClassifier()
```

Run the ridge classifier with the token count features.

```{python}
#| echo: true
scores = model_selection.cross_val_score(clf, 
                                         train_vectors, train_df["target"],
                                         cv=5, scoring="f1")
scores
```

## Ridge Classifier

Run the ridge classifier with the tf-idf features.

```{python}
#| echo: true
scores = model_selection.cross_val_score(clf, 
                                         train_vectors_tfid, train_df["target"],
                                         cv=5, scoring="f1")
scores
```

## Logistic Regression

```{python}
#| echo: true
logistic = linear_model.LogisticRegression()
scores = model_selection.cross_val_score(logistic, train_vectors, train_df["target"], cv=5, scoring="f1")
scores
```

[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)

## Creating a submission file

```{python}
#| echo: true
logistic.fit(train_vectors, train_df["target"])
sample_submission = pd.read_csv("kaggle/input/nlp-getting-started/sample_submission.csv")
sample_submission["target"] = logistic.predict(test_vectors)
sample_submission.to_csv("submission.csv", index=False)
```
